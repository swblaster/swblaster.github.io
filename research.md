---
layout: default
title: Research
permalink: /research/
---

# Scalable Parallel Training Algorithms for Deep Convolutional Neural Networks
*This project is an individual research project for my Ph.D. thesis at Northwestern University.*

Training deep and large neural networks is extremely compute-intensive. Considering the ever-increasing available training data, reducing the training time is critical to make deep learning more practical. For large-scale classification problems, for example 1000-class ImageNet classification, training a modern Convolutional Neural Network (CNN) takes hours or even days. Our goal of this project is to study the internal behaviors of neural network and design scalable parallel training algorithms based on such understandings.
